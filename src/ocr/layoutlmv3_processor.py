import pytesseract
import cv2
import numpy as np
import re
import tkinter as tk
from tkinter import ttk
import collections 
from collections import Counter

# Dimensiones est√°ndar del documento
IMAGE_WIDTH = 669
IMAGE_HEIGHT = 425

# Coordenadas de la zona de texto en la parte frontal
ZONE_FRONT = (3, 91, 432, 180)

# Coordenadas de las zonas clave en la parte trasera
ZONES_BACK = {
    "Fecha de nacimiento": (416, 43, 210, 39),
    "Sexo": (460, 138, 93, 37),
    "Lugar de expedicion": (346, 190, 147, 35),
}

ITERACIONES = 20

def resize_image(image: np.ndarray) -> np.ndarray:
    """ Redimensiona la imagen a 669x425 si no tiene ese tama√±o. """
    h, w = image.shape[:2]
    if w != IMAGE_WIDTH or h != IMAGE_HEIGHT:
        image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_AREA)
    return image


def clean_text(text: str, only_numbers=False, only_letters=False) -> str:
    """ Filtra caracteres no deseados, permitiendo solo letras o n√∫meros seg√∫n el caso. """
    text = text.strip()
    text = re.sub(r"[^a-zA-Z0-9√Å√â√ç√ì√ö√ë√°√©√≠√≥√∫√±\s.-]", "", text)

    if only_numbers:
        text = re.sub(r"[^0-9]", "", text)
    elif only_letters:
        text = re.sub(r"[^a-zA-Z√Å√â√ç√ì√ö√ë√°√©√≠√≥√∫√±\s]", "", text)

    return text

def clean_document_number(text):
    """
    Limpia el n√∫mero de documento eliminando caracteres no num√©ricos,
    asegurando que el primer d√≠gito no se pierda.
    """
    # Mantener solo los n√∫meros y eliminar cualquier otro car√°cter
    cleaned_text = re.sub(r"[^\d]", "", text)
    
    # Aplicar la correcci√≥n solo si tiene 10 o m√°s d√≠gitos
    if len(cleaned_text) >= 10:
        if cleaned_text[0] != "1":
            cleaned_text = "1" + cleaned_text[1:]  # Reemplaza el primer d√≠gito por 1


    # Si el primer d√≠gito es "0", eliminarlo para evitar errores en la interpretaci√≥n
    cleaned_text = cleaned_text.lstrip("0")

    return cleaned_text

def extract_front_zone(image: np.ndarray) -> dict:
    """ Extrae texto de la parte frontal y muestra la zona recortada. """
    image = resize_image(image)
    x, y, w, h = ZONE_FRONT
    zone = image[y:y+h, x:x+w]

    text = pytesseract.image_to_string(zone, lang="spa", config="--psm 6").strip()

    return parse_front_text(text)

def parse_front_text(text: str) -> dict:
    """ Analiza el texto detectado y extrae din√°micamente el n√∫mero de documento, apellidos y nombres. """
    lines = text.split("\n")
    lines = [line.strip() for line in lines if line.strip()]

    numero_doc = "No detectado"
    apellidos = "No detectado"
    nombres = "No detectado"

    # üö´ Lista de palabras/frases que NO deben estar en Apellidos o Nombres
    palabras_invalidas = [
    # Encabezados oficiales y t√©rminos generales
    "REP√öBLICA DE COLOMBIA", "REPUBLICA DE COLOMBIA", "REPUBLICA DE COLOMB1A", "REPUBLI√áA DE COLOMBIA",
    "IDENTIFICACION PERSONAL", "IDENTIFICACI√ìN PERSONAL", "IDENTIFICAC10N PERSONAL", "IDENTIFICAC10N PERS0NAL",
    "C√âDULA DE CIUDADANIA", "C√âDULA DE CIUDADAN√çA", "CEDULA DE CIUDADANIA", "CEDULA DE CIUDADAN√çA",
    "C3DULA DE CIUDADANIA", "C3DULA DE CIUDADAN√çA", "C√âDULA D3 CIUDADANIA", "C√âDULA DE CIUDADAN1A",
    "C√âDULA DE CIUD4DANIA", "DOCUMENTO", "DE IDENTIDAD", "IDENTIDAD", "TARJETA", "DE IDENTIFICACI√ìN",

    # N√∫meros y t√©rminos relacionados
    "NUMERO", "N√öMERO", "NUM3RO", "N√öM3RO", "NUMER0", "N0MERO", "N√öMERO.", "N√öMER0", "NRO", "N¬∞",

    # Palabras que aparecen en la parte superior de los documentos
    "APELLIDOS", "APELIDOS", "APELLDIOS", "ARPELLIDOS", "APELLIDIOS", "ARELLIDOS", "APELILIDOS",
    "NOMBRES", "N0MBRES", "NOMBR3S", "NOMBRES.", "NOMRES", "NOMB.", "NOMBRE", "NOMBRES Y APELLIDOS",

    # Fechas y lugares
    "FECHA", "EXPEDICI√ìN", "EXPEDICION", "EXP3DICI√ìN", "EXP3DICION", "LUGAR DE NACIMIENTO",
    "LUGAR DE EXPEDICION", "LUGAR DE EXPEDICI√ìN", "LUGAR NACIMIENTO", "EXPEDIDO EN", "EXPEDIDO",

    # Otros campos comunes en documentos de identidad
    "ESTATURA", "SEXO", "MASCULINO", "FEMENINO", 
    "ESTADO CIVIL", "ESTADOCIVIL", "LUGAR", "DE EXPEDICI√ìN", "DE NACIMIENTO", "EXPE.", "LUGAR EXPE.",

    # Errores OCR comunes y variaciones
    "APE.LIDOS", "AP.ELLIDOS", "APEL.LIDOS", "APELLI.DOS", "APELLID.OS", "A.PELLIDOS", "APEL.LID.OS",
    "A.PE.LLIDOS", "APELL.IDOS", "APE.LLIDOS", "APEL.LIDOS.", "APELLI.DO.S", "APELL.ID.OS", "APELLI.D.OS",
    "AP.EL.LIDOS", "A.PELL.IDOS", "AP.ELL.IDOS", "A.PE.LL.IDOS", "APELLID.O.S", "APELL.IDO.S", "APE.LLID.OS",
    "APEL.LID.OS", "APEL.LI.DOS", "APELL.I.DOS", "APE.LI.DOS", "APEL.LI.D.O.S", "AP.ELL.IDO.S.", "A.PELL.IDO.S",
    "A.PE.LL.I.DOS", "AP.ELLI.D.O.S", "APEL.LI.D.O.S", "A.PE.LLI.D.O.S", "AP.ELL.ID.O.S.", "A.PELL.ID.O.S",
    "A.PE.L.LI.DOS", "APELLID.O.S", "APE.LI.D.OS", "APELLI.D.O.S.", "A.PELL.I.DOS", "AP.ELLI.DOS",

    # Variaciones y errores en nombres
    "APELLIDOS:", "APELIDOS:", "NOMBRES:", "NOMBR3S:", "APELLIDOS Y NOMBRES:", "NOMBRES Y APELLIDOS:",
    "NOMBRES/APELLIDOS:", "NOMBRE Y APELLIDO:", "APELLIDOS Y NOMBRE:", "NOMBR3S/APELLIDOS:", "NOMB. APELL.",
    "NOMB. Y APELL.", "NOMBRES APELLIDOS:", "APELLIDOS NOMBRES:", "APELLIDOS/NOMBRES:", "NOMBRES/APELLIDOS:"
]

    

    for line in lines:
        
        # üîç Detectar n√∫mero de documento
        if numero_doc == "No detectado":
            line = clean_document_number(line)

        match = re.search(r"[\d.]{6,15}", line)
        if match and numero_doc == "No detectado":
            numero_doc = match.group().replace(",", ".")
            numero_doc = match.group().lstrip("0")
 
        
        # üîç Detectar apellidos
        elif any(word in line.upper() for word in palabras_invalidas):
            continue  # Si la l√≠nea contiene palabras prohibidas, la ignoramos
        elif apellidos == "No detectado" or apellidos == "":
            apellidos = line.upper()

        # üîç Detectar nombres
        elif nombres == "No detectado":
            nombres = line.upper()

    apellidos == clean_text(apellidos)
    nombres == clean_text(nombres)

    return {
        "N√∫mero de Documento": numero_doc,
        "Apellidos": apellidos,
        "Nombres": nombres
    }


def extract_zones(image: np.ndarray, zones: dict) -> dict:
    """ Extrae texto de la parte trasera, muestra cada zona recortada y aplica validaci√≥n. """
    image = resize_image(image)

    extracted_data = {}
    for key, (x, y, w, h) in zones.items():
        zone = image[y:y+h, x:x+w]


        text = pytesseract.image_to_string(zone, lang="spa", config="--psm 6").strip()
        text = clean_text(text)

        # Guardar solo la primera l√≠nea detectada en "Sexo" y "Lugar de expedici√≥n"
        if key in ["Sexo", "Lugar de expedicion"]:
            text_lines = text.split("\n")
            text = text_lines[0] if text_lines else "No detectado"
        
        extracted_data[key] = text

    return validate_fields(extracted_data)


def validate_fields(data: dict) -> dict:
    """ Verifica que los campos tengan valores v√°lidos y corrige errores. """
    valid_sex_values = ["M", "m", "F", "f", "T", "t", "NB"]

    # Validar el campo "Sexo"
    if "Sexo" in data:
        detected_sex = data["Sexo"].upper().strip()
        if detected_sex not in valid_sex_values:
            data["Sexo"] = "No detectado"

    # Validar el campo "Lugar de expedici√≥n" (solo letras)
    if "Lugar de expedicion" in data:
        data["Lugar de expedicion"] = clean_text(data["Lugar de expedicion"], only_letters=True)
        if not data["Lugar de expedicion"]:
            data["Lugar de expedicion"] = "No detectado"

    return data
    
def show_progress():
    """ Muestra una ventana emergente con una barra de carga. """
    root = tk.Tk()
    root.title("Procesando documento")
    ttk.Label(root, text="Procesando documento, por favor espere...").pack(pady=10)
    progress = ttk.Progressbar(root, orient="horizontal", length=300, mode="determinate")
    progress.pack(pady=10)
    return root, progress


def process_document(front_image_path: str, back_image_path: str) -> dict:
    """ Procesa ambas partes del documento y extrae la informaci√≥n. """
    try:
        front_image = cv2.imread(front_image_path)
        back_image = cv2.imread(back_image_path)

        if front_image is None or back_image is None:
            raise Exception("No se pudo cargar una de las im√°genes. Verifica que las rutas sean correctas.")

        front_data_temp = {}
        back_data_temp = {}

        root, progress = show_progress()
        root.update()

        for i in range(ITERACIONES):
            progress["value"] = (i + 1) * (100 / ITERACIONES)
            root.update()
            front_data_temp[i] = extract_front_zone(front_image)
            back_data_temp[i] = extract_zones(back_image, ZONES_BACK)

        # Convertir a un formato hashable antes de usar Counter
        front_counts = Counter(frozenset(d.items()) for d in front_data_temp.values())
        back_counts = Counter(frozenset(d.items()) for d in back_data_temp.values())

        # Obtener los valores m√°s repetidos
        front_data = dict(front_counts.most_common(1)[0][0])  # Convertir de nuevo a diccionario
        back_data = dict(back_counts.most_common(1)[0][0])  # Convertir de nuevo a diccionario
        
        root.destroy()

        return {"Parte Frontal": front_data, "Parte Trasera": back_data}

    except Exception as e:
        raise Exception(f"Error al procesar el documento: {str(e)}")
